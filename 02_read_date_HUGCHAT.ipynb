{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_read_date_HUGCHAT.ipynb\n",
    "# Reads the PDFs and extracts the portion of text contained in the section 'Modalità di apertura delle offerte'; the texts are saved in a CSV file.  \n",
    "# Use https://huggingface.co/chat/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force to reload extrernal modules every new cell execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT ###\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os \n",
    "from dotenv import load_dotenv # Needed to load the contents of the .env file\n",
    "from hugchat import hugchat\n",
    "from hugchat.login import Login\n",
    "import requests\n",
    "from time import sleep as t_sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOCAL IMPORT ###\n",
    "from config import config_reader\n",
    "from utilities import read_csv_data_to_df, convert_dmy_to_ymd, left_join_df, calculate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBALS ###\n",
    "yaml_config = config_reader.config_read_yaml(\"config.yml\", \"config\")\n",
    "# print(yaml_config) # debug\n",
    "data_dir = str(yaml_config[\"DATA_DIR\"])\n",
    "bid_file_text = str(yaml_config[\"FILE_BID_TEXT\"])\n",
    "bid_file_text_date = str(yaml_config[\"FILE_BID_TEXT_DATE\"])\n",
    "bid_file_text_date_label = str(yaml_config[\"FILE_BID_TEXT_DATE_LABEL\"])\n",
    "csv_sep = str(yaml_config[\"CSV_SEP\"])\n",
    "\n",
    "# HugChat\n",
    "load_dotenv() # Load environment variables from the .env file\n",
    "hc_username = os.getenv(\"HC_EMAIL\")\n",
    "hc_password = os.getenv(\"HC_PASS\")\n",
    "time_sleep = int(yaml_config[\"TIME_SLEEP\"]) # To avoid too many requests in a short time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_test(username:str, passwd:str) -> None:\n",
    "    \"\"\"\n",
    "    Test the connection to the LLM.\n",
    "    \n",
    "    Args:\n",
    "        username (str): login e-mail.\n",
    "        passwd (str): login password.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Hugging Face Login\n",
    "        session = Login(username, passwd)\n",
    "        if session.login():\n",
    "            print(\"OK! Successful login to LLM\")\n",
    "        else:\n",
    "            print(\"ERROR! Login failed: invalid session.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR! An unexpected error occurred in LLM test connection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for generating LLM response\n",
    "def llm_find_date(text:str, cookies:requests.cookies.RequestsCookieJar):\n",
    "    \"\"\"\n",
    "    Extracts and formats a date from a given text string using HuggingChat. The date is returned in the format dd/mm/yyyy.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text from which the date needs to be extracted. It should contain a date in any recognisable format.\n",
    "        cookies (requests.cookies): Cookie to avoid login.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the date in dd/mm/yyyy format. If an error occurs, it returns the error message.\n",
    "    \"\"\"\n",
    "    # Create ChatBot\n",
    "    try:\n",
    "        prompt_input = f\"Please extract and format only the date in this Italian text as yyyy-mm-dd, without adding anything other than the date. Dates can be written as dd.mm.yyyy or dd/mm/yyyy and days and months less than 10 may not have the leading 0 (e.g.: 5.2.2016). Write -1 if date not found. Text: {text}\"\n",
    "        chatbot = hugchat.ChatBot(cookies=cookies.get_dict())\n",
    "        response = chatbot.chat(prompt_input)\n",
    "        print(\"LLM output:\", response)\n",
    "        # print(type(response)) # debug\n",
    "        return response    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR! An unexpected error occurred during the LLM prompt use: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row: pd.Series, cookies:requests.cookies.RequestsCookieJar) -> str:\n",
    "    \"\"\"\n",
    "    Process a single row of the DataFrame. If the 'text' field is not None, call llm_find_date() with the 'text'.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A pandas Series object representing a single row.\n",
    "        cookies (requests.cookies): Cookie to avoid login.\n",
    "    Returns:\n",
    "        str: The date string returned by llm_find_date if 'text' is not None; otherwise, None.\n",
    "    \"\"\"\n",
    "    if pd.notnull(row['text']):\n",
    "        print(\"LLM input:\", row['text'])\n",
    "        t_sleep(time_sleep) # Avoid too many requests\n",
    "        return llm_find_date(row['text'], cookies)\n",
    "    return None  # Return None if 'text' is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** PROGRAM START ***\n",
      "\n",
      "Start process: 2024-05-16 09:38:35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### MAIN ###\n",
    "print()\n",
    "print(\"*** PROGRAM START ***\")\n",
    "print()\n",
    "\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Start process:\", str(start_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reading CSV file\n",
      "File: data/bid_opening_text.csv\n",
      "Reading CSV with input col_type...\n",
      "Rows in dataframe: 1063\n",
      "Columns in dataframe: Index(['file_name', 'case_id', 'text'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading CSV file text and dates to be extracted by LLM\n",
    "print(\">> Reading CSV file\")\n",
    "path_bid_text = Path(data_dir) / bid_file_text\n",
    "print(\"File:\", str(path_bid_text))\n",
    "dic_type = {\"file_name\":object, \"case_id\":object, \"text\":object}\n",
    "df_bid_text = read_csv_data_to_df(path_bid_text, dic_type, csv_sep)\n",
    "df_bid_text_len = len(df_bid_text)\n",
    "print(\"Rows in dataframe:\", df_bid_text_len)\n",
    "print(\"Columns in dataframe:\", df_bid_text.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reading the annotated dataset (with dates as labels)\n",
      "Path: data/bid_opening_text_date_label.csv\n",
      "Reading CSV with input col_type...\n",
      "Dataframe with labels shape: (1063, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\">> Reading the annotated dataset (with dates as labels)\")\n",
    "path_csv_label = Path(data_dir) / bid_file_text_date_label\n",
    "print(\"Path:\", str(path_csv_label))\n",
    "dic_type = {\"file_name\":object, \"text\":object, \"label\":object}\n",
    "df_label = read_csv_data_to_df(path_csv_label, dic_type, csv_sep)\n",
    "print(\"Dataframe with labels shape:\", df_label.shape) # should be same shape as df_bid_text\n",
    "# Convert labels\n",
    "df_label['label_ymd'] = df_label['label'].apply(convert_dmy_to_ymd)\n",
    "# Replace empty cells (not found) with -1\n",
    "df_label.loc[df_label['label_ymd'].isna(), 'label_ymd'] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Testing LLM connection\n",
      "OK! Successful login to LLM\n"
     ]
    }
   ],
   "source": [
    "# Testing the connection to LLM\n",
    "print(\">> Testing LLM connection\")\n",
    "# print(\"Open API key:\", openai_api_key) # debug\n",
    "llm_test(hc_username, hc_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Reading CSV text and querying LLM\n",
      "LLM input: Data: 25/10/2017|Ora locale: 09:00|Luogo:|Rignano Flaminio — Piazza IV Novembre 1 — sede comunale.|Informazioni relative alle persone ammesse e alla procedura di apertura:|Come da normativa e dagli atti di gara.\n",
      "LLM output: 2017-10-25\n",
      "LLM input: Data: 28.11.2018 - 10:00|Luogo:|Tarcento, Piazza Roma 7|Persone ammesse ad assistere all'apertura delle offerte: sì|Informazioni complementari sulle persone ammesse e la procedura di apertura: La procedura è di evidenza |pubblica.\n",
      "LLM output: 2018-11-28\n",
      "LLM input: Data: 22/08/2018|Ora locale: 08:30|Luogo:|Presso la Sede della C.U.C. dell’Unione dei Comuni del Frignano|Via Giardini 15 (sala al 3o piano)|Pavullo nel Frignano (MO)\n",
      "LLM output: 2018-08-22\n",
      "LLM input: Luogo:|Le offerte dovranno pervenire in modalità telematica e l'apertura avverrà sulla piattaforma telematica Sintel |Regione Lombardia\n",
      "LLM output: -1\n",
      "LLM input: Data: 05/12/2017|Ora locale: 10:30|Luogo:|Gambassi Terme Via Garibaldi 7.|Informazioni relative alle persone ammesse e alla procedura di apertura:|Vedi disciplinare.\n",
      "LLM output: 2017-12-05\n",
      "LLM input: Data: 11.3.2016 - 10:00|Persone ammesse ad assistere all'apertura delle offerte: sì|Informazioni complementari sulle persone ammesse e la procedura di apertura: Seduta aperta al pubblico.\n",
      "LLM output: 2016-03-11\n",
      "LLM input: Data: 15/01/2019|Ora locale: 09:30|Luogo:|Via Paganini 22 — 09025 Sanluri (SU) — Italia\n",
      "LLM output: 2019-01-15\n",
      "LLM input: Data: 30/08/2017|Ora locale: 9:30|Luogo:|Comune di Riva Presso Chieri — Piazza Parrocchia 4.|Informazioni relative alle persone ammesse e alla procedura di apertura:|Legali rappresentanti e/o delegati.\n",
      "LLM output: 2017-08-30\n",
      "LLM input: Data: 19.5.2016 - 9:30|Luogo:|Sede legale del Comune di Buaggiano, Piazza Matteotti 2.|Persone ammesse ad assistere all'apertura delle offerte: sì|Informazioni complementari sulle persone ammesse e la procedura di apertura: Seduta pubblica.\n",
      "LLM output: 2016-05-19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parse the files\n",
    "print(\">> Reading CSV text and querying LLM\")\n",
    "# If you only want a sample of the rows, uncomment the following line to extract a random sample of 10 rows\n",
    "df_bid_text = df_bid_text.sample(n=10)\n",
    "\n",
    "# Hugging Face Login\n",
    "sign = Login(hc_username, hc_password)\n",
    "cookies = sign.login()\n",
    "\n",
    "# Applies LLM on the dataframe \n",
    "df_bid_text['date'] = df_bid_text.apply(lambda row: process_row(row, cookies), axis=1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> New data obtained from LLM\n",
      "Index(['file_name', 'case_id', 'text', 'date'], dtype='object')\n",
      "                     file_name     case_id  \\\n",
      "468  2017-OJS180-368850-it.pdf  2017368850   \n",
      "702  2018-OJS194-440333-it.pdf  2018440333   \n",
      "647  2018-OJS136-311074-it.pdf  2018311074   \n",
      "716  2018-OJS202-460935-it.pdf  2018460935   \n",
      "489  2017-OJS208-430527-it.pdf  2017430527   \n",
      "\n",
      "                                                  text        date  \n",
      "468  Data: 25/10/2017|Ora locale: 09:00|Luogo:|Rign...  2017-10-25  \n",
      "702  Data: 28.11.2018 - 10:00|Luogo:|Tarcento, Piaz...  2018-11-28  \n",
      "647  Data: 22/08/2018|Ora locale: 08:30|Luogo:|Pres...  2018-08-22  \n",
      "716  Luogo:|Le offerte dovranno pervenire in modali...          -1  \n",
      "489  Data: 05/12/2017|Ora locale: 10:30|Luogo:|Gamb...  2017-12-05  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\">> New data obtained from LLM\")\n",
    "# df_bid_text['date'].fillna(\"-1\", inplace=True)\n",
    "# Replace empty cells (not found) with -1\n",
    "df_bid_text.loc[df_bid_text['date'].isna(), 'date'] = \"-1\"\n",
    "print(df_bid_text.columns)\n",
    "print(df_bid_text.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Saving bid opening texts and dates\n",
      "Dataframe with dates shape: (10, 4)\n",
      "Path: data/bid_opening_text_date_OAI.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a file with the texts extracted from the PDFs\n",
    "print(\">> Saving bid opening texts and dates\")\n",
    "print(\"Dataframe with dates shape:\", df_bid_text.shape)  # should be same shape as df_label\n",
    "file_name = Path(bid_file_text_date).stem # get the general filename without extension\n",
    "file_name_csv = f\"{file_name}_OAI.csv\"\n",
    "path_out = Path(data_dir) / file_name_csv\n",
    "print(\"Path:\", path_out)\n",
    "df_bid_text.to_csv(path_out, sep=csv_sep, index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Checking accuracy against the annotated dataset\n",
      "Dates from LLM length: 9\n",
      "Dates from LABELS length: 993\n",
      "\n",
      "Dataframe for accuracy\n",
      "Dataframe length: 9\n",
      "                   file_name     case_id        date       label   label_ymd\n",
      "0  2017-OJS180-368850-it.pdf  2017368850  2017-10-25  25/10/2017  2017-10-25\n",
      "1  2018-OJS194-440333-it.pdf  2018440333  2018-11-28  28/11/2018  2018-11-28\n",
      "2  2018-OJS136-311074-it.pdf  2018311074  2018-08-22  22/08/2018  2018-08-22\n",
      "3  2018-OJS202-460935-it.pdf  2018460935          -1         NaN         NaN\n",
      "4  2017-OJS208-430527-it.pdf  2017430527  2017-12-05  05/12/2017  2017-12-05\n",
      "Index(['file_name', 'case_id', 'date', 'label', 'label_ymd'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy against the annotated dataset\n",
    "print(\">> Checking accuracy against the annotated dataset\")\n",
    "\n",
    "# Only extracts dates found (!= -1)\n",
    "df_bid_text = df_bid_text[df_bid_text['date'] != \"-1\"]\n",
    "print(\"Dates from LLM length:\", len(df_bid_text)) # should be same length as label_dates_list\n",
    "\n",
    "# Only extracts labels (!= -1)\n",
    "df_label = df_label[df_label['label_ymd'] != \"-1\"]\n",
    "print(\"Dates from LABELS length:\", len(df_label))  # should be same length as llm_dates_list\n",
    "\n",
    "print()\n",
    "\n",
    "# Merges the dataset from which the dates were extracted with the one containing the labels\n",
    "key_col = \"file_name\" # Key column on which to perform the join\n",
    "col_del = [\"text\"] # List of columns to be removed from the join\n",
    "merged_df = left_join_df(df_bid_text, df_label, key_col, col_del)\n",
    "\n",
    "print(\"Dataframe for accuracy\")\n",
    "print(\"Dataframe length:\", len(merged_df))\n",
    "print(merged_df.head())\n",
    "print(merged_df.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00 over a sample of 9 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing precision\n",
    "accuracy = calculate_accuracy(merged_df, \"date\", \"label_ymd\")\n",
    "print(f\"Accuracy: {accuracy:.2f} over a sample of {len(merged_df)} rows\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End process: 2024-05-16 09:39:35\n",
      "Time to finish: 0:01:00\n",
      "\n",
      "\n",
      "*** PROGRAM END ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# program end\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "delta_time = end_time - start_time\n",
    "\n",
    "print()\n",
    "print(\"End process:\", end_time)\n",
    "print(\"Time to finish:\", delta_time)\n",
    "print()\n",
    "\n",
    "print()\n",
    "print(\"*** PROGRAM END ***\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
