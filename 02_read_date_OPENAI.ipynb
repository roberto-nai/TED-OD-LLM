{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_read_date_OPENAI.ipynb\n",
    "# Reads the PDFs and extracts the portion of text contained in the section 'Modalit√† di apertura delle offerte'; the texts are saved in a CSV file.\n",
    "# Use https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force to reload extrernal modules every new cell execution\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT ###\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os \n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv # Needed to load the contents of the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOCAL IMPORT ###\n",
    "from config import config_reader\n",
    "from utilities import read_csv_data_to_df, convert_dmy_to_ymd, left_join_df, calculate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GLOBALS ###\n",
    "yaml_config = config_reader.config_read_yaml(\"config.yml\", \"config\")\n",
    "# print(yaml_config) # debug\n",
    "data_dir = str(yaml_config[\"DATA_DIR\"])\n",
    "csv_sep = str(yaml_config[\"CSV_SEP\"])\n",
    "sample_size = int(yaml_config[\"TEST_SAMPLE\"]) \n",
    "\n",
    "# INPUT\n",
    "dic_lan = {\"DE\":0, \"ES\":0, \"FR\":0, \"IT\":1, \"PT\":0} # <-- INPUT: set 1 for the desired language; set only one language at time\n",
    "bid_file_text = str(yaml_config[\"FILE_BID_TEXT\"]) # the input file with text from which extract dates\n",
    "bid_file_text_date_label = str(yaml_config[\"FILE_BID_TEXT_DATE_LABEL\"]) # the label file based on FILE_BID_TEXT\n",
    "\n",
    "# OUTPUT\n",
    "bid_file_text_date = str(yaml_config[\"FILE_BID_TEXT_DATE\"]) # the output files with dates\n",
    "log_llm = str(yaml_config[\"LOG_PDF_LLM\"]) \n",
    "log_llm_header = str(yaml_config[\"LOG_PDF_LLM_HEADER\"]) \n",
    "log_llm = str(yaml_config[\"LOG_PDF_LLM\"]) \n",
    "log_llm_header = str(yaml_config[\"LOG_PDF_LLM_HEADER\"])\n",
    "\n",
    "# OpenAI\n",
    "load_dotenv() # Load environment variables from the .env file\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "suffix = \"OAI\" # CSV suffix containing LLM results\n",
    "openai_model_name = str(yaml_config[\"OPENAI_MODEL_NAME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_test(model_name:str) -> None:\n",
    "    \"\"\"\n",
    "    Test the connection to the LLM.\n",
    "    \n",
    "    Parameters:\n",
    "        model_name (str): Name of the model.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    try:\n",
    "        stream = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Say this is a test connection [OK]\"}],\n",
    "        stream=True,\n",
    "        )\n",
    "        for chunk in stream:\n",
    "                print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR! An unexpected error occurred in LLM test connection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_find_date(text: str, model_name:str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts and formats a date from a given text string using ChatGPT. The date is returned in the format dd/mm/yyyy.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text from which the date needs to be extracted. It should contain a date in any recognisable format.\n",
    "        model_name (str): Name of the model.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representing the date in dd/mm/yyyy format. If an error occurs, it returns the error message.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant in finding dates in Italian texts\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Please extract and format only the date in this Italian text as yyyy-mm-dd, without adding anything other than the date. Dates can be written as dd.mm.yyyy or dd/mm/yyyy and days and months less than 10 may not have the leading 0 (e.g.: 5.2.2016). Write -1 if date not found: {text}\"}\n",
    "                    ],\n",
    "            model=model_name,\n",
    "        )\n",
    "        # print(type(chat_completion)) # debug\n",
    "        # ChatCompletion(id='chatcmpl-9MrwkHcMyDloWUBVqAcWaSv9vr8B2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='25/02/2016', role='assistant', function_call=None, tool_calls=None))], created=1715237614, model='gpt-4-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=6, prompt_tokens=132, total_tokens=138))\n",
    "        # The chat_completion vaiable contains a response object ChatCompletion that is is a list of data\n",
    "        # The textual response is in: choices[0] -> message -> content\n",
    "        chat_response = chat_completion.choices[0].message.content.strip()\n",
    "        print(\"LLM output:\", chat_response) # debug\n",
    "        print(\"-\"*3)\n",
    "        return chat_response\n",
    "        # for more than one response: generated_texts = [choice.message[\"content\"].strip() for choice in chat_completion[\"choices\"]]\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR! An unexpected error occurred in LLM find date: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row: pd.Series, model_name:str) -> str:\n",
    "    \"\"\"\n",
    "    Process a single row of the DataFrame. If the 'text' field is not None, call llm_find_date() with the 'text'.\n",
    "\n",
    "    Parameters:\n",
    "        row (pd.Series): A pandas Series object representing a single row.\n",
    "        model_name (str): Name of the model.\n",
    "    Returns:\n",
    "        str: The date string returned by llm_find_date if 'text' is not None; otherwise, None.\n",
    "    \"\"\"\n",
    "    if pd.notnull(row['text']):\n",
    "        print(\"LLM input:\", row['text'])\n",
    "        return llm_find_date(row['text'], model_name)\n",
    "    return None  # Return None if 'text' is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN ###\n",
    "print()\n",
    "print(\"*** PROGRAM START ***\")\n",
    "print()\n",
    "\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Start process:\", str(start_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Settings\n",
      "Desired language code for LLM: IT\n",
      "File input: data/bid_opening_text_IT.csv\n",
      "File input with labels: data/bid_opening_text_IT_date_label.csv\n",
      "File output: data/bid_opening_text_IT_date_llm.csv\n"
     ]
    }
   ],
   "source": [
    "print(\">> Settings\")\n",
    "lang_code = None\n",
    "key_with_value_1 = [key for key, value in dic_lan.items() if value == 1]\n",
    "if key_with_value_1: \n",
    "    lang_code = key_with_value_1[0]\n",
    "print(\"Desired language code for LLM:\", lang_code)\n",
    "\n",
    "# input\n",
    "bid_file_text_lang = bid_file_text.replace(\"LANG\", lang_code)\n",
    "path_bid_text_lang = Path(data_dir) / bid_file_text_lang\n",
    "print(\"File input:\", path_bid_text_lang)\n",
    "\n",
    "bid_file_text_date_label_lang = bid_file_text_date_label.replace(\"LANG\", lang_code)\n",
    "path_bid_text_lang_label = Path(data_dir) / bid_file_text_date_label_lang\n",
    "print(\"File input with labels:\", path_bid_text_lang_label)\n",
    "\n",
    "# output\n",
    "bid_file_text_date_lang = bid_file_text_date.replace(\"LANG\", lang_code)\n",
    "path_bid_text_lang_llm = Path(data_dir) / bid_file_text_date_lang\n",
    "print(\"File output:\", path_bid_text_lang_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Preparing the output timing log\n",
      "File created with header: data/ted_log_pdf_llm.csv\n"
     ]
    }
   ],
   "source": [
    "print(\">> Preparing the output timing log\")\n",
    "path_log = Path(data_dir) / log_llm\n",
    "if not path_log.exists():\n",
    "    # If the file does not exist, create it with the specified header\n",
    "    with path_log.open(mode='w') as fp:\n",
    "        fp.write(f\"{log_llm_header}\\n\")\n",
    "    print(f\"File created with header: {path_log}\")\n",
    "else:\n",
    "    print(f\"The file already exists: {path_log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV file text and dates to be extracted by LLM\n",
    "print(\">> Reading CSV input file\")\n",
    "path_bid_text = Path(data_dir) / bid_file_text\n",
    "print(\"File:\", str(path_bid_text))\n",
    "dic_type = {\"file_name\":object, \"case_id\":object, \"text\":object, \"text_date\":object}\n",
    "df_bid_text = read_csv_data_to_df(path_bid_text, dic_type, csv_sep)\n",
    "df_bid_text_len = len(df_bid_text)\n",
    "print(\"Rows in dataframe:\", df_bid_text_len)\n",
    "print(\"Columns in dataframe:\", df_bid_text.columns)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV file text and annotated as labels\n",
    "print(\">> Reading the annotated dataset (with dates as labels)\")\n",
    "path_csv_label = Path(data_dir) / bid_file_text_date_label\n",
    "print(\"Path:\", str(path_csv_label))\n",
    "dic_type = {\"file_name\":object, \"text\":object, \"label\":object}\n",
    "df_label = read_csv_data_to_df(path_csv_label, dic_type, csv_sep)\n",
    "# Convert labels\n",
    "df_label['label_ymd'] = df_label['label'].apply(convert_dmy_to_ymd)\n",
    "# Replace empty cells (not found) with -1\n",
    "df_label.loc[df_label['label_ymd'].isna(), 'label_ymd'] = \"-1\"\n",
    "print(\"Rows in dataframe with labels:\", df_bid_text_len)\n",
    "print(\"Columns in dataframe with labels:\", df_bid_text.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the connection to LLM\n",
    "print(\">> Testing LLM connection\")\n",
    "# print(\"Open API key:\", openai_api_key) # debug\n",
    "print(\"Model name:\", openai_model_name)\n",
    "llm_test(openai_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the files\n",
    "print(\">> Reading CSV text and querying LLM\")\n",
    "\n",
    "# If sample_size is greater than 0 it extracts a sample of rows from the dataset\n",
    "if sample_size > 0:\n",
    "    if sample_size > df_bid_text_len:\n",
    "        sample_size = df_bid_text_len\n",
    "    print(f\"Using a sample of size {sample_size}\")\n",
    "    df_bid_text = df_bid_text.sample(n=sample_size)\n",
    "else:\n",
    "    print(\"Using the entire dataframe\")\n",
    "    df_bid_text = df_bid_text  # Optionally, you can add df_bid_text = df_bid_text.copy() to make it explicit that no sampling is applied\n",
    "print()\n",
    "\n",
    "# Applies LLM on the dataframe \n",
    "print(\"Query at LLM started\")\n",
    "print()\n",
    "df_bid_text['date'] = df_bid_text.apply(lambda row: process_row(row, openai_model_name), axis=1)\n",
    "print()\n",
    "print(\"Query at LLM concluded\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> New data obtained from LLM\")\n",
    "# df_bid_text['date'].fillna(\"-1\", inplace=True)\n",
    "# Replace empty cells (not found) with -1\n",
    "df_bid_text.loc[df_bid_text['date'].isna(), 'date'] = \"-1\"\n",
    "df_bid_text_len = len(df_bid_text)\n",
    "print(\"Rows in dataframe:\", df_bid_text_len)\n",
    "print(\"Columns in dataframe:\", df_bid_text.columns)\n",
    "print(df_bid_text.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file with the texts extracted from the PDFs\n",
    "print(\">> Saving bid opening texts and dates\")\n",
    "print(\"Dataframe with dates shape:\", df_bid_text.shape)  # should be same shape as df_label\n",
    "file_name = Path(bid_file_text_date).stem # get the general filename without extension\n",
    "file_name_csv = f\"{file_name}_{suffix}.csv\"\n",
    "path_out = Path(data_dir) / file_name_csv\n",
    "print(\"Path:\", path_out)\n",
    "df_bid_text.to_csv(path_out, sep=csv_sep, index=False, quoting=csv.QUOTE_ALL)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking accuracy against the annotated dataset\n",
    "print(\">> Checking accuracy against the annotated dataset\")\n",
    "\n",
    "# Only extracts dates found (!= -1)\n",
    "df_bid_text = df_bid_text[df_bid_text['date'] != \"-1\"]\n",
    "print(\"Dates from LLM length:\", len(df_bid_text)) # should be same length as label_dates_list\n",
    "\n",
    "# Only extracts labels (!= -1)\n",
    "df_label = df_label[df_label['label_ymd'] != \"-1\"]\n",
    "print(\"Dates from LABELS length:\", len(df_label))  # should be same length as llm_dates_list\n",
    "\n",
    "print()\n",
    "\n",
    "# Merges the dataset from which the dates were extracted with the one containing the labels\n",
    "key_col = \"file_name\" # Key column on which to perform the join\n",
    "col_del = [\"text\"] # List of columns to be removed from the join\n",
    "merged_df = left_join_df(df_bid_text, df_label, key_col, col_del)\n",
    "\n",
    "print(\"Dataframe joint for accuracy\")\n",
    "print(\"Dataframe length:\", len(merged_df))\n",
    "print(merged_df.head())\n",
    "print(merged_df.columns)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing precision\n",
    "accuracy = calculate_accuracy(merged_df, \"date\", \"label_ymd\")\n",
    "print(f\"Accuracy: {accuracy:.2f} over a sample of {len(merged_df)} rows\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# program end\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "delta_time = end_time - start_time\n",
    "\n",
    "print()\n",
    "print(\"End process:\", end_time)\n",
    "print(\"Time to finish:\", delta_time)\n",
    "print()\n",
    "\n",
    "print()\n",
    "print(\"*** PROGRAM END ***\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
